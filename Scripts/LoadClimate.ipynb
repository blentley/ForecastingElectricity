{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading weather data into PostgreSQL\n",
    "*Author: Blake Bentley*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare environment\n",
    "import pandas as pd\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import psycopg2 as pg\n",
    "import io\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(\"C:/Users/Blake/Documents/UTS/36102_iLab_1/Client/Climate/\")\n",
    "# You will need subdirectories below this called 'Historical' and 'Historical/Data'\n",
    "# Put the reference data in Historical. Put the text files containing the data into Historical/Data\n",
    "\n",
    "# Define this data path\n",
    "fnpath = '''Historical/Data/'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define input parameters for connecting to the database\n",
    "user_name = r\"postgres\"\n",
    "user_pass = r\"password\"\n",
    "db_name = r\"endgame\"\n",
    "server = r\"localhost\"\n",
    "\n",
    "# Connection string\n",
    "strEngine = r'postgresql://' + user_name+ \"@\" + server + \"/\" + db_name\n",
    "\n",
    "# Define for weather data\n",
    "loadSchema = \"bom\"\n",
    "# Define table name for station reference\n",
    "tblStationRef = \"station_ref\"\n",
    "# Define table name for weather data\n",
    "tblWeather = \"weather\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The stations definItion file\n",
    "Begin by loading the station reference table. This table provides meta information on each weather station. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the stations definition file using the following headers\n",
    "statdefNames = ['st', 'station_id', 'rain_dist_c', 'station_name', 'open_d', 'clse_d'\n",
    ", 'latd', 'lgtd', 'coord_src', 'state', 'elev', 'barom_elev', 'wmo_id', 'efft_d', 'expy_d'\n",
    ", 'pc_complete', 'pc_qual_y', 'pc_qual_n', 'pc_qual_w', 'pc_qual_s', 'pc_qual_i', 'symbol']\n",
    "\n",
    "# Read the file in\n",
    "statdef = pd.read_csv(\"Historical/HM01X_StnDet_999999999395130.txt\"\n",
    "                      , header = None\n",
    "                      , names = statdefNames\n",
    "                      , index_col = 'station_id')\n",
    "statdef.head()\n",
    "del statdefNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean up the table\n",
    "# 1. Drop the redundant fields\n",
    "statdefDel = ['st', 'symbol', 'elev', 'barom_elev', 'wmo_id', 'coord_src']\n",
    "statdef = statdef.drop(statdefDel, axis = 1)\n",
    "statdef.head()\n",
    "del statdefDel\n",
    "\n",
    "# 2. Strip white space from name\n",
    "statdef['station_name'] = statdef['station_name'].str.strip()\n",
    "statdef.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the station reference table into postgres\n",
    "# Define a connection string \n",
    "engine = create_engine(strEngine)\n",
    "\n",
    "# Write the table\n",
    "statdef.to_sql(tblStationRef, engine, schema = loadSchema)\n",
    "\n",
    "# Check the table exists \n",
    "print (engine.has_table(tblStationRef, schema = loadSchema))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the weather collected for each station\n",
    "Each weather station has a file containing timestamped measures of climate. The following steps will read these files into python, cleanse and prepare them for load into a PostgreSQL database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the column headers as a list of names\n",
    "weatherName = ['rec_id', 'station_id', 'lcl_yr', 'lcl_mnth', 'lcl_day', 'lcl_hr', 'lcl_min'\n",
    ",'std_yr', 'std_mnth', 'std_day', 'std_hr', 'std_min', 'air_temp', 'qual_flag', 'aws', 'symbol']\n",
    "\n",
    "# Define the types to load the data as\n",
    "weatherType = {'rec_id':np.object, 'station_id':np.object, 'lcl_yr':np.int32, 'lcl_mnth':np.int32\n",
    ", 'lcl_day':np.int32, 'lcl_hr':np.int32, 'lcl_min':np.int32, 'std_yr':np.int32, 'std_mnth':np.int32\n",
    ", 'std_day':np.int32, 'std_hr':np.int32, 'std_min':np.int32, 'air_temp':np.object, 'qual_flag':np.object\n",
    ", 'aws':np.object, 'symbol':np.object}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now begin the loop\n",
    "\n",
    "# Begin the loop\n",
    "for fn in os.listdir(fnpath):\n",
    "    print (os.path.join(fnpath, fn))\n",
    "    \n",
    "    # Read in the file\n",
    "    fnname = os.path.join(fnpath, fn)\n",
    "    thisfile = pd.read_csv(fnname, skiprows=1, names=weatherName, dtype=weatherType, na_values=\" \")\n",
    "    \n",
    "    # Drop some cols\n",
    "    thisfileDel = ['lcl_yr', 'lcl_mnth', 'lcl_day', 'lcl_hr', 'lcl_min', 'aws', 'symbol', 'rec_id']\n",
    "    thisfile = thisfile.drop(thisfileDel, axis = 1)\n",
    "    \n",
    "    # Create a datetime column\n",
    "    thisfile.index = pd.to_datetime(dict(year = thisfile.std_yr\n",
    "                                         , month = thisfile.std_mnth\n",
    "                                         , day = thisfile.std_day\n",
    "                                         , hour = thisfile.std_hr\n",
    "                                         , minute = thisfile.std_min))\n",
    "    \n",
    "    # Drop some more cols\n",
    "    thisfileDel = ['std_yr', 'std_mnth', 'std_day', 'std_hr', 'std_min']\n",
    "    thisfile = thisfile.drop(thisfileDel, axis = 1)\n",
    "    \n",
    "    # Strip the whitespace from the air temp and station ID column\n",
    "    thisfile['air_temp'] = thisfile['air_temp'].str.strip()\n",
    "    thisfile['station_id'] = thisfile['station_id'].str.strip()\n",
    "    \n",
    "    # Then change the column type\n",
    "    thisfile['air_temp'] = pd.to_numeric(thisfile['air_temp'], errors='coerce')\n",
    "    \n",
    "    #thisfile.head()\n",
    "    #thisfile.info()\n",
    "    \n",
    "    # With the data set clean, load it into the database\n",
    "    thisfile.to_sql(tblWeather, engine, schema = loadSchema, if_exists='append')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finish by putting an index on the station ID field in the database\n",
    "engine.execute(\"create index idx_station_weather on \" + loadSchema + \".\" + tblWeather + \"using btree (station_id);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('jupyter nbconvert --to html LoadClimate.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
